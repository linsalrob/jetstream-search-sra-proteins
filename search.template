
Universe = vanilla

Requirements = SRA_Data_Mounted == True
Rank = DaemonStartTime
request_cpus = 1
request_memory = 9 GB
request_disk = 5 GB

executable = ../search.sh
arguments = $REF_BASENAME $SRA_ID_LIST

transfer_input_files = ../proteins.dmnd
transfer_output_files = $OUTPUT_FILES

Output = $JOB_COUNT.out
Error = $JOB_COUNT.err

Log = ../jobs.log

should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# Send the job to Held state on failure
on_exit_hold = (ExitBySignal == True) || (ExitCode != 0)

# Periodically retry the jobs every 3 minutes for a certain number of tries
periodic_release = NumJobStarts < 5 && (CurrentTime - EnteredCurrentStatus) > 3*60

# remove failed jobs after retries
periodic_remove = JobStatus == 5 && NumJobStarts >= 5

# extra attributes
+wf_run_id = "$RUN_ID"
+airavata_username = "$AIRAVATA_USERNAME"

queue 1

